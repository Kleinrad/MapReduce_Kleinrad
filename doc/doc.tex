\documentclass[12pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[backend=biber]{biblatex}
\usepackage{float}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage[newfloat]{minted}
\usepackage{caption}
\usepackage{dirtree}
\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000
\addbibresource{references.bib}

\newenvironment{code}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Source Code}

\graphicspath{{img/}}

\title{MapReduce‚ÄêSystem (37)}
\author{Fabian Kleinrad (07), 5BHIF}
\date{March 2022}

\begin{document}

\begin{titlepage}
\maketitle
\end{titlepage}

\tableofcontents
\newpage

\section{Introduction}

In this project the technology MapReduce is being simulated. Thereby a simple system has been developed to imitate a the functionality of an MapReduce application. All of the functionality in this project is written with C++17 and compiled with the help of the meson build system\footfullcite{meson}. The communication is based on the TCP protocol and realized using the C++ library asio\footfullcite{asio}.\newline
Furthermore to increase performance and usability protocol buffers\footfullcite{protobuf} are utilized. Protocol Buffers enable the serialization of data structures in an efficient manner, which simplifies working with messages sent between parties in the MapReduce system.\newline
To make use of the advantages of using a MapReduce architecture, a simple use-case consisting of counting the number of character occurrences in a plain text document. This kind of application was chosen due to its simplicity, which enables the focus of this project to stay on MapReduce rather than a test application. 

\section{MapReduce}

MapReduce is a programming model developed to decrease computation time of large data sets. It was invented by Google, the reason being the need to compute various kinds of derived data. Examples would be inverted indices or representations of the graph structure of web documents. These applications all have simplicity in common, there are no complex operations needed to accomplish said tasks. Furthermore are these kinds of processes characterized by accepting large amounts of input data and reducing it to fraction of itself. MapReduce presents a solution to parallelization, fault-tolerance, data distribution and load balancing. Thereby it is based on the principle of map and reduce, which are eponymous for the technology.\footfullcite{mapreducePaper}

\subsection{Input Data}

MapReduce processes unstructured or semi-structured data. The system is designed to accept large amounts of data in bulk. In the first step of the MapReduce process, this data is being split into subsets, to allow for data distribution. The way this data is being divided depends on the implementation and the type of input data present. The result of splitting the raw data is a set of key/value pairs.\footfullcite{uniLeibzigMapReduce}

\subsection{Map}

The map function accepts a set of key/value pairs, with the implementation being provided by the user. Result of this phase is once more a set of key/value pairs. These result pairs represent the significant information contained in the input data. These significant data pairs directly influence the result and all unneeded information is being discarded. The name map stems form assigning a quantity attribute which represents the value of the resulting pairs, to an quality attribute.\footcite{uniLeibzigMapReduce}\footcite{mapreducePaper}

\subsection{Reduce}

Sorted key/value pairs get passed to the reduce function, which groups and thereby reduces the set of data points. The logic of this grouping functionality depends on the application MapReduce is used for. For that reason the reduce function is also implemented by the user.\footcite{uniLeibzigMapReduce}

\pagebreak

\subsection{Additional Phases}

\subsubsection{Shuffle}
In most implementations of a MapReduce model an shuffle phase is carried out, between the map and reduce phase. The shuffle phase is used to sort the resulting key/value pairs from the mapping phase. This is done in an effort to group similar keys into clusters which can than be reduced by a single worker.\footcite{uniLeibzigMapReduce}\newline

\subsubsection{Combine}
To reduce the network traffic an additional combine phase can be used after mapping. Thereby the large amount of key/value pairs resulting from the mapping phase get reduced before they get transferred over the network. However, because of this local aggregation of data it is possible to slow down the instead through shuffling optimized process of reducing data.\footfullcite{hadoop}

\section{Class-diagram}


\subsection{Classes}


\section{Implementation}


\section{Usage}
\label{usage}

\subsection{Command Line Arguments}

\subsubsection{Configuration}


\newpage

\section{Project Structure}


% .bib include & references
\newpage

\printbibliography
\end{document}